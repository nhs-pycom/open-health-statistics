---
title: "GitHub API call"
comments: false
---

# `pull_raw_save_df` function

## Description

This function pulls raw GitHub repository data for multiple organisations and returns a consolidated DataFrame.

## Signature

```python
from typing import Dict
import pandas as pd

def pull_raw_save_df(github_org_dict: Dict[str, str], csv_path: str, max_retries: int = 3) -> pd.DataFrame:
    """
    Pulls raw GitHub repository data for multiple organisations and returns a consolidated DataFrame.

    Args:
        github_org_dict (dict): A dictionary containing GitHub organisations to fetch repositories for.
            Values should be organisation names.
        csv_path (str): The path to the CSV file containing previously fetched data.
        max_retries (int, optional): The maximum number of times to retry the API request if a rate limit is encountered.
            Defaults to 3.

    Returns:
        pd.DataFrame: A Pandas DataFrame containing information about repositories for all specified organisations.
    """
    if os.path.exists(csv_path):
        df = pd.read_csv(csv_path)
        fetched_repos = set(df['id'])
    else:
        df = pd.DataFrame()
        fetched_repos = set()

    for org in github_org_dict.values():
        page = 1
        retries = 0
        while True:
            try:
                raw_data = fetch_public_repos(org, page=page)
                repos_count = len(raw_data)
                logging.info(f"{org} repo count = {repos_count}")

                if repos_count == 0:
                    break

                parsed_data = parse_github_repos(raw_data)
                new_data = parsed_data[~parsed_data['id'].isin(fetched_repos)]
                df = pd.concat([df, new_data], axis=0)
                fetched_repos.update(new_data['id'].values)

                if repos_count < 100:
                    break
                else:
                    page += 1

            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 403:
                    logging.warning(f"Rate limit exceeded for organization {org}.")
                    if retries >= max_retries:
                        logging.warning(f"Max retries exceeded for organization {org}. Moving on.")
                        break
                    reset_time = int(e.response.headers.get("X-RateLimit-Reset"))
                    wait_time = reset_time - time.time() + 1
                    logging.info(f"Waiting {wait_time} seconds until rate limit is reset.")
                    time.sleep(wait_time)
                    retries += 1
                else:
                    logging.error(f"Error fetching data for {org}: {e}")
                    break

    df.drop_duplicates(subset='id', keep='first', inplace=True)
    df.to_csv(csv_path, index=False)
    return df
```

## Parameters

- github_org_dict: A dictionary containing GitHub organizations to fetch repositories for. Values should be organisation names and organisation github names.
- csv_path: The path to the CSV file containing previously fetched data.
- max_retries: The maximum number of times to retry the API request if a rate limit is encountered. Defaults to 3.

## Returns

- pd.DataFrame: A Pandas DataFrame containing information about repositories for all specified organizations.

## Example Usage

```python
import utilities.github_api_calls as github_api_call

df = github_api_call.pull_raw_save_df({'Open AI': 'openai', 'Google': 'google'}, 'github_repos.csv')
```